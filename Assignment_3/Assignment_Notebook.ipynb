{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Part 1: Cosine Similarities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DYvTKDHydfvl"
      },
      "outputs": [],
      "source": [
        "from gensim.models import FastText\n",
        "from scipy import spatial\n",
        "\n",
        "def get_sentence_embedding(model, sentence):\n",
        "  # This method takes in the trained model and the input sentence\n",
        "  # and returns the embedding of the sentence as the average embedding\n",
        "  # of its words\n",
        "  words = sentence.split(\" \")\n",
        "  vector = model.wv[words[0]].copy()\n",
        "  for i in range(1, len(words)):\n",
        "    vector += model.wv[words[i]]\n",
        "  return vector/len(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MZMUJTSPIRhD"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from post_parser_record import PostParserRecord\n",
        "\n",
        "def read_tsv_test_data(file_path):\n",
        "  # Takes in the file path for test file and generate a dictionary\n",
        "  # of question id as the key and the list of question ids similar to it\n",
        "  # as value. It also returns the list of all question ids that have\n",
        "  # at least one similar question\n",
        "  dic_similar_questions = {}\n",
        "  lst_all_test = []\n",
        "  with open(file_path) as fd:\n",
        "    rd = csv.reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
        "    for row in rd:\n",
        "        question_id = int(row[0])\n",
        "        lst_similar = list(map(int, row[1:]))\n",
        "        dic_similar_questions[question_id] = lst_similar\n",
        "        lst_all_test.append(question_id)\n",
        "        lst_all_test.extend(lst_similar)\n",
        "  return dic_similar_questions, lst_all_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Nwg4E-_NKtBa"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "def generate_negative_samples(dic, lst_of_ids):\n",
        "  new_dic = {}\n",
        "  lst = []\n",
        "  cnt = 0\n",
        "  for id in dic:\n",
        "    for value in dic[id]:\n",
        "      cnt += 1\n",
        "      lst.append(value)\n",
        "    new_dic[id] = []\n",
        "    for _ in range(cnt):\n",
        "      while True:\n",
        "        random_item = random.choice(lst_of_ids)\n",
        "        if random_item not in lst:\n",
        "          break\n",
        "      new_dic[id].append(random_item)\n",
        "    cnt = 0\n",
        "  return new_dic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qMqUxsQNIRhE"
      },
      "outputs": [],
      "source": [
        "# Get IDs for the questions we are testing for similar questions\n",
        "positive_samples_id, lst_all_test = read_tsv_test_data(\"duplicate_questions.tsv\")\n",
        "post_reader = PostParserRecord(\"Posts_law.xml\" )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iur5SXxJMXNN"
      },
      "outputs": [],
      "source": [
        "lst_of_ids = []\n",
        "for id in post_reader.map_questions:\n",
        "  lst_of_ids.append(id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "p0C89idkVS76"
      },
      "outputs": [],
      "source": [
        "# Helper method to get and format similar questions from id\n",
        "def get_text_from_id(post_reader, dic):\n",
        "  lst = []\n",
        "  for id in dic:\n",
        "    question = post_reader.map_questions[id]\n",
        "    key = question.title + \" \" + question.body\n",
        "    key = re.sub('<[^<]+?>', '', key)\n",
        "    values = []\n",
        "    for value in dic[id]:\n",
        "      question = post_reader.map_questions[value]\n",
        "      text = question.title + \" \" + question.body\n",
        "      text = re.sub('<[^<]+?>', '', text)\n",
        "      values.append(text)\n",
        "    lst.append([key, values])\n",
        "  return lst"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a list of all the questions and answers use to train our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IJ1XUtNUTKf9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\shady\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import re\n",
        "# Collecting sentences from questions and answers\n",
        "lst_training_sentences = []\n",
        "for question_id in post_reader.map_questions:\n",
        "    if question_id in lst_all_test:\n",
        "        continue\n",
        "    question = post_reader.map_questions[question_id]\n",
        "    title_sentences = nltk.sent_tokenize(question.title)\n",
        "    processed_titles = []\n",
        "    for sentence in title_sentences:\n",
        "        sentence = re.sub('<[^<]+?>', '', sentence)\n",
        "        words = nltk.word_tokenize(sentence)\n",
        "        processed_titles.append(words)\n",
        "    body_sentences = nltk.sent_tokenize(question.body)\n",
        "    process_bodies = []\n",
        "    for sentence in body_sentences:\n",
        "        sentence = re.sub('<[^<]+?>', '', sentence)\n",
        "        words = nltk.word_tokenize(sentence)\n",
        "        process_bodies.append(words)\n",
        "    # Collecting sentences from title and body\n",
        "    lst_training_sentences.extend(processed_titles)\n",
        "    lst_training_sentences.extend(process_bodies)\n",
        "\n",
        "    lst_answers = question.answers\n",
        "    if lst_answers is not None:\n",
        "        for answer in lst_answers:\n",
        "            answer_sentences = nltk.sent_tokenize(answer.body)\n",
        "            processed_answers = []\n",
        "            for sentence in answer_sentences:\n",
        "                sentence = re.sub('<[^<]+?>', '', sentence)\n",
        "                words = nltk.word_tokenize(sentence)\n",
        "                processed_answers.append(words)\n",
        "            lst_training_sentences.extend(processed_answers)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "O3KUriOLARX_"
      },
      "outputs": [],
      "source": [
        "def train_model(lst_sentences):\n",
        "  model = FastText(vector_size = 100, window = 5, min_n=1, sg = 1)\n",
        "  model.build_vocab(corpus_iterable=lst_sentences)\n",
        "  model.train(corpus_iterable=lst_sentences, total_examples=len(lst_sentences), epochs=10)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CJXGntqaAWhv"
      },
      "outputs": [],
      "source": [
        "# Train your model\n",
        "model = train_model(lst_training_sentences)\n",
        "model.save(\"fast.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = FastText.load(\"fast.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper method to get vector representation\n",
        "import numpy as np\n",
        "def get_all_embeddings(model, dic, map):  \n",
        "    new_dic = {}\n",
        "    for id in dic:\n",
        "        question = map[id]\n",
        "        title = re.sub('<[^<]+?>', '', question.title)\n",
        "        body = re.sub('<[^<]+?>', '', question.body)\n",
        "        title_sentences = nltk.sent_tokenize(title)\n",
        "        body_sentences = nltk.sent_tokenize(body)\n",
        "        lst_title_embed = []\n",
        "        lst_body_embed = []\n",
        "        for sentence in title_sentences:\n",
        "            lst_title_embed.append(get_sentence_embedding(model, sentence))\n",
        "        avg_title_embed = np.mean(lst_title_embed, axis=0)\n",
        "        for sentence in body_sentences:\n",
        "            lst_body_embed.append(get_sentence_embedding(model, sentence))\n",
        "        avg_body_embed = np.mean(lst_body_embed, axis=0)\n",
        "        new_dic[id] = [avg_title_embed, avg_body_embed]\n",
        "    return new_dic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_embeddings = get_all_embeddings(model, post_reader.map_questions, post_reader.map_questions)\n",
        "all_positive_embeddings = get_all_embeddings(model, positive_samples_id, post_reader.map_questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cosine_similarity_model(model, all_embeddings, all_positive_embeddings, positive_samples_id):\n",
        "  # Finding similar questions using fastText model\n",
        "  dictionary_result_by_title = {}\n",
        "  dictionary_result_by_body = {}\n",
        "  for test_question_id in positive_samples_id:\n",
        "    max_title_similarity = -1\n",
        "    max_body_similarity = -1\n",
        "    most_similar_question_id_by_title = -1\n",
        "    most_similar_question_id_by_body = -1\n",
        "    for question_id in all_embeddings:\n",
        "      # We are not comparing a question with itself\n",
        "      if question_id == test_question_id:\n",
        "        continue\n",
        "\n",
        "      # Calculate the cosine similarity between the questions\n",
        "      title_similarity = 1 - spatial.distance.cosine(all_positive_embeddings[test_question_id][0], all_embeddings[question_id][0])\n",
        "      body_similarity = 1 - spatial.distance.cosine(all_positive_embeddings[test_question_id][1], all_embeddings[question_id][1])\n",
        "\n",
        "      # Save the question id with the highest cosine similarity\n",
        "      if title_similarity > max_title_similarity:\n",
        "        max_title_similarity = title_similarity\n",
        "        most_similar_question_id_by_title = question_id\n",
        "\n",
        "      if body_similarity > max_body_similarity:\n",
        "        max_body_similarity = title_similarity\n",
        "        most_similar_question_id_by_body = question_id\n",
        "        \n",
        "    dictionary_result_by_title[test_question_id] = most_similar_question_id_by_title\n",
        "    dictionary_result_by_body[test_question_id] = most_similar_question_id_by_body\n",
        "\n",
        "  # Calculate average P@1\n",
        "  p_at_1_sum = 0\n",
        "  for id in dictionary_result_by_title:\n",
        "    if dictionary_result_by_title[id] in positive_samples_id[id]:\n",
        "      #print(f\"title match: {dictionary_result_by_title[id]}\")\n",
        "      p_at_1_sum += 1\n",
        "  p_at_1_avg_by_title = p_at_1_sum / len(dictionary_result_by_title)\n",
        "  print(f\"{p_at_1_sum} matches out of {len(dictionary_result_by_title)} questions\")\n",
        "  print(f\"p@1 average for question titles: {p_at_1_avg_by_title}\")\n",
        "  # Calculate average P@1\n",
        "  p_at_1_sum = 0\n",
        "  for id in dictionary_result_by_body:\n",
        "    if dictionary_result_by_body[id] in positive_samples_id[id]:\n",
        "      #print(f\"body match: {dictionary_result_by_body[id]}\")\n",
        "      p_at_1_sum += 1\n",
        "  p_at_1_avg_by_body = p_at_1_sum / len(dictionary_result_by_body)\n",
        "  print(f\"{p_at_1_sum} matches out of {len(dictionary_result_by_body)} questions\")\n",
        "  print(f\"p@1 average for question bodies: {p_at_1_avg_by_body}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32 matches out of 282 questions\n",
            "p@1 average for question titles: 0.11347517730496454\n",
            "9 matches out of 282 questions\n",
            "p@1 average for question bodies: 0.031914893617021274\n"
          ]
        }
      ],
      "source": [
        "cosine_similarity_model(model, all_embeddings, all_positive_embeddings, positive_samples_id)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Part 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class FeedForwardNeuralNetwork(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim_1, hidden_dim_2, output_dim):\n",
        "    super(FeedForwardNeuralNetwork, self).__init__()\n",
        "\n",
        "    self.layer_1 = nn.Linear(input_dim, hidden_dim_1)\n",
        "    self.relu_1 = nn.ReLU()\n",
        "\n",
        "    self.layer_2 = nn.Linear(hidden_dim_1, hidden_dim_2)\n",
        "    self.relu_2 = nn.ReLU()\n",
        "    \n",
        "    self.layer_3 = nn.Linear(hidden_dim_2, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.layer_1(x)\n",
        "    out = self.relu_1(out)\n",
        "\n",
        "    out = self.layer_2(out)\n",
        "    out = self.relu_2(out)\n",
        "    \n",
        "    out = self.layer_3(out)\n",
        "    return torch.sigmoid(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class myModel():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    input_dim = 100 \n",
        "    hidden_dim_1 = 128\n",
        "    hidden_dim_2 = 64\n",
        "    out_dim = 1 \n",
        "\n",
        "    model = FeedForwardNeuralNetwork(input_dim, hidden_dim_1, hidden_dim_2, out_dim)\n",
        "\n",
        "    # loss function\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "    # moving to GPU if available\n",
        "    model.to(device)\n",
        "    criterion = criterion.to(device)\n",
        "\n",
        "    def calculate_accuracy(self, y_true, y_pred):\n",
        "        y_pred = torch.round(y_pred)\n",
        "        correct = (y_true == y_pred).float()\n",
        "        acc = correct.sum() / len(correct)\n",
        "        return acc\n",
        "\n",
        "    def training(self, tfidfX_train, Y_train, tfidfX_val, Y_val, num_epochs):\n",
        "        batch_size = 200\n",
        "        X_train_mini_batches = torch.split(tfidfX_train, batch_size)\n",
        "        Y_train_mini_batches = torch.split(Y_train, batch_size)\n",
        "\n",
        "        train_losses = []\n",
        "        train_accuracies = []\n",
        "        val_losses = []\n",
        "        val_accuracies = []\n",
        "\n",
        "        best_accuracy = 0\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            epoch_loss = 0\n",
        "            epoch_accuracy = 0\n",
        "            validation_loss = 0\n",
        "            val_accuracy = 0\n",
        "            for X_train_mini_batch, Y_train_mini_batch in zip(X_train_mini_batches, Y_train_mini_batches):\n",
        "                X_train_mini_batch = X_train_mini_batch.to(self.device)\n",
        "                Y_train_mini_batch = Y_train_mini_batch.to(self.device)\n",
        "\n",
        "                # forward pass\n",
        "                train_prediction = self.model.forward(X_train_mini_batch.float())\n",
        "\n",
        "                # returns a tensor with all the dimensions of input of size 1 removed\n",
        "                train_prediction = torch.squeeze(train_prediction)\n",
        "\n",
        "                # calculate loss\n",
        "                train_loss = self.criterion(train_prediction, Y_train_mini_batch)\n",
        "\n",
        "                # clearing up acculated gradients\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                # getting gradients\n",
        "                train_loss.backward()\n",
        "\n",
        "                # updating parameters\n",
        "                self.optimizer.step()\n",
        "\n",
        "                # add each mini batch's loss\n",
        "                epoch_loss += train_loss.item()\n",
        "\n",
        "                # add each mini batch's accuracy\n",
        "                epoch_accuracy += self.calculate_accuracy(Y_train_mini_batch, train_prediction)\n",
        "\n",
        "            tfidfX_val = tfidfX_val.to(self.device)\n",
        "            Y_val = Y_val.to(self.device)\n",
        "\n",
        "            # Forward pass to get output\n",
        "            val_prediction = self.model.forward(tfidfX_val.float())\n",
        "            val_prediction = torch.squeeze(val_prediction)\n",
        "\n",
        "            # Calculate Loss\n",
        "            val_loss = self.criterion(val_prediction, Y_val)\n",
        "            # print(val_loss)\n",
        "            # Add each mini batch's loss\n",
        "            validation_loss = val_loss.item()\n",
        "\n",
        "            # Add each mini batch's accuracy\n",
        "            val_accuracy = self.calculate_accuracy(Y_val, val_prediction)\n",
        "            if val_accuracy > best_accuracy:\n",
        "                torch.save(self.model.state_dict(), 'best_model_state.bin')\n",
        "                best_accuracy = val_accuracy\n",
        "\n",
        "    def __loadModel(self, ):\n",
        "        self.model.load_state_dict(torch.load('best_model_state.bin'))\n",
        "\n",
        "    def calc(self, Y_true, Y_pred):\n",
        "        Y_true_list = Y_true.cpu().tolist()\n",
        "        Y_pred_list = Y_pred.cpu().tolist()\n",
        "        TP = TN = FP = FN = 0\n",
        "        for true_label, predicted_label in zip(Y_true_list, Y_pred_list):\n",
        "            predicted_label = round(predicted_label)\n",
        "            if true_label == 1 and predicted_label == 1:\n",
        "                TP += 1\n",
        "            elif true_label == 0 and predicted_label == 0:\n",
        "                TN += 1\n",
        "            elif true_label == 0 and predicted_label == 1:\n",
        "                FP += 1\n",
        "            elif true_label == 1 and predicted_label == 0:\n",
        "                FN += 1\n",
        "        return TP, TN, FP, FN\n",
        "\n",
        "    def test(self, tfidfX_test, Y_test):\n",
        "        self.__loadModel()\n",
        "        tfidfX_test = tfidfX_test.to(self.device)\n",
        "        Y_test = Y_test.to(self.device)\n",
        "        # forward pass to get output\n",
        "        test_prediction = self.model.forward(tfidfX_test.float())\n",
        "        test_prediction = torch.squeeze(test_prediction)\n",
        "\n",
        "        # calculate accuracy\n",
        "        test_accuracy = self.calculate_accuracy(Y_test, test_prediction)\n",
        "\n",
        "        print(Y_test)\n",
        "        print(test_prediction)\n",
        "\n",
        "        TP, TN, FP, FN = self.calc(Y_test, test_prediction)\n",
        "\n",
        "\n",
        "        print(\"True Positives:\", TP)\n",
        "        print(\"True Negatives:\", TN)\n",
        "        print(\"False Positives:\", FP)\n",
        "        print(\"False Negatives:\", FN)\n",
        "        print(\"Test Accuracy:\", round(test_accuracy.item(), 4), \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_all_embeddings_both(model, dic, map):  \n",
        "    new_dic = {}\n",
        "    for id in dic:\n",
        "        question = map[id]\n",
        "        title = re.sub('<[^<]+?>', '', question.title)\n",
        "        body = re.sub('<[^<]+?>', '', question.body)\n",
        "        title_sentences = nltk.sent_tokenize(title)\n",
        "        body_sentences = nltk.sent_tokenize(body)\n",
        "        lst_embed = []\n",
        "        for sentence in title_sentences:\n",
        "            lst_embed.append(get_sentence_embedding(model, sentence))\n",
        "        for sentence in body_sentences:\n",
        "            lst_embed.append(get_sentence_embedding(model, sentence))\n",
        "        avg_embed1 = np.mean(lst_embed, axis=0)\n",
        "        question = map[dic[id][0]]\n",
        "        title = re.sub('<[^<]+?>', '', question.title)\n",
        "        body = re.sub('<[^<]+?>', '', question.body)\n",
        "        title_sentences = nltk.sent_tokenize(title)\n",
        "        body_sentences = nltk.sent_tokenize(body)\n",
        "        lst_embed = []\n",
        "        for sentence in title_sentences:\n",
        "            lst_embed.append(get_sentence_embedding(model, sentence))\n",
        "        for sentence in body_sentences:\n",
        "            lst_embed.append(get_sentence_embedding(model, sentence))\n",
        "        avg_embed2 = np.mean(lst_embed, axis=0)\n",
        "        new_dic[id] = avg_embed1 + avg_embed2\n",
        "    return new_dic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "negative_samples_id = generate_negative_samples(positive_samples_id, lst_of_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_positive_embeddings_both = get_all_embeddings_both(model, positive_samples_id, post_reader.map_questions)\n",
        "all_negative_embeddings_both = get_all_embeddings_both(model, negative_samples_id, post_reader.map_questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training begins\n",
            "tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
            "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
            "        0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
            "        0., 1., 0.])\n",
            "tensor([1.5784e-01, 9.9880e-01, 1.9526e-01, 5.6627e-01, 4.9733e-02, 5.0210e-02,\n",
            "        2.7983e-04, 4.5946e-02, 1.1795e-02, 8.9183e-01, 4.3503e-01, 4.6777e-01,\n",
            "        5.5502e-01, 5.7859e-01, 4.9181e-02, 7.4047e-01, 8.7407e-01, 6.1477e-02,\n",
            "        1.0639e-01, 9.8863e-01, 7.7202e-01, 5.3641e-03, 3.3013e-03, 9.9052e-01,\n",
            "        2.6276e-02, 9.9962e-01, 1.4722e-01, 9.3124e-01, 5.4761e-01, 7.9023e-01,\n",
            "        6.9279e-02, 9.9985e-01, 7.0472e-01, 9.8708e-01, 3.0379e-01, 7.7190e-03,\n",
            "        6.4215e-02, 9.6759e-01, 2.5972e-03, 9.9031e-01, 4.0365e-02, 9.8776e-01,\n",
            "        4.2870e-01, 9.9969e-01, 4.7910e-01, 5.5010e-01, 8.3100e-01, 4.8961e-01,\n",
            "        6.6822e-02, 6.0577e-01, 9.9883e-01, 9.8310e-01, 9.3793e-01, 9.9759e-01,\n",
            "        9.6483e-01, 4.0996e-01, 2.0680e-02], grad_fn=<SqueezeBackward0>)\n",
            "True Positives: 20\n",
            "True Negatives: 20\n",
            "False Positives: 9\n",
            "False Negatives: 8\n",
            "Test Accuracy: 0.7018 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from post_parser_record import PostParserRecord\n",
        "\n",
        "modelFeedForward = myModel()\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "for id in positive_samples_id:\n",
        "    x.append(all_positive_embeddings_both[id])\n",
        "    y.append(1)\n",
        "    x.append(all_negative_embeddings_both[id])\n",
        "    y.append(0)\n",
        "# Split the data into three sets\n",
        "train_size = int(0.8 * len(x))\n",
        "val_size = int(0.1 * len(x))\n",
        "\n",
        "training_x = x[:train_size]\n",
        "training_y = y[:train_size]\n",
        "\n",
        "val_x = x[train_size:train_size+val_size]\n",
        "val_y = y[train_size:train_size+val_size]\n",
        "\n",
        "test_x = x[train_size+val_size:]\n",
        "test_y = y[train_size+val_size:]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# (Question 1, Question 2)\n",
        "# 0 = not duplicate, 1 = duplicate\n",
        "training_x = torch.from_numpy(np.asarray(training_x)).type(torch.FloatTensor)\n",
        "training_y = torch.from_numpy(np.asarray(training_y)).type(torch.FloatTensor)\n",
        "val_x = torch.from_numpy(np.asarray(val_x)).type(torch.FloatTensor)\n",
        "val_y = torch.from_numpy(np.asarray(val_y)).type(torch.FloatTensor)\n",
        "print(\"training begins\")\n",
        "modelFeedForward.training(training_x, training_y, val_x, val_y, 180)\n",
        "\n",
        "test_x = torch.from_numpy(np.asarray(test_x)).type(torch.FloatTensor)\n",
        "test_y = torch.from_numpy(np.asarray(test_y)).type(torch.FloatTensor)\n",
        "modelFeedForward.test(test_x, test_y)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
